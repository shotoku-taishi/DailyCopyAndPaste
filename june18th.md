Abstract. The increasing availability and use of artificial intelligence (AI) tools in educational settings has raised concerns about student`s overreliance on these technologies. 
Overreliance occurs when individuals accept incorrrect AI-generated recommendations, often without critical evaluation, leading to flawed problem solutions and undermining learning
ouccomes. This study investigates potential factors ontributing to patterns of AI reliance among undergraduate students, examining not only overreliance but also apprpriate 
reliance (correctly accepting helpful and rejecting harmful recommendations) and underreliance (incorrectly rejecting helpful recommendations). Our approach comvinedpre- and post-surveys
with a controlled ex@erimental task where participants solved programming problems with an AI assistant that provided both accurate and deliberately incorrect suggestions, allowing
direct observation of students' programming self-efficiency, programming literacy, and need for cognition(The mental action or process of acquiring knowledge and understanding through 
tought, experience, and the senses.), while showing negative correlations with post-task trust and satisfaction. Overreliance showed significant correlations with post-task trust and satisfaction
with the AI assistant. Underreliance was negatively corelated with post-task trust and satisfaction with the AI assistant. Undereliance was negatively correlated with programming 
literacy, programming self-efficacy, and need for cognition. Overall, the findings provid insights for developing targeted interventions that promote appropriate reliance on AI tools, with implications 
for the integration of AI in curriculum and educational technoogies.


In short: currently, many students rely on AI tools to complete their school homeworks. Overreliance on AI tools are correlated with the sel-efficacy, programming literay, and need 
for cognition. In this document, we will learn appropriate was to use AI tool for school carriculum.


The use of artificial intelligence (AI) in higher education has increased dramatically with the development of large language models such as OpenAI's Chat GPT, ANthropic's Claude,
and Microsoft's Copliot. These AI assistants offer students easy to access, and often times, free support in tasks through instant feedback, explanations, and problem solving 
assistance. Student's adoption of these technologies has been substantial, with recent research finding that 64.5% of surveyed undergraduate students use AI chatbots at leas once 
a week.with 90.4%reporting prior experience with these systems. While prior research has examined why students initially adopt AI tools, focusign on factors like perceived
usefulness and ease of use, the widespread adoption of these tools has introduced a new challenge that remains understudiedl students' reliance on AI. Following the frame work obtained by
[28], we distinguish between three primary forms of reliance: appripriate reliance, overreliance, and underreliance. Appropriate reliance occurs when students correctly accept
helpful AI reccommendations and reject flawed(not perfect, or containing mistakes) ones, demonstrating calibrated trust and critical evaluationl overreliance occurs when users 
acept flawed or incorrect AI-generated recommendations without verification; and underreliance occurs when students reject accurate AI recommendations.

When students overrely on AI outputs, it can undermine learning outcomes and reduce their development of critical thinking skills. AI hallucinations(false perception of objects or 
events involving your senses sight, sound, smell, touch and taste.) can introduce "inaccuracies or fabrications(writing in a fictional form.)" that can propagate through academic
work. Students themselves express concerns about peers using AI "as a crutch" and losing the ability to think for themsleves. These concerns are particularly sailent
in education, where students face competing pressures: the immediate need to complete assignments efficiently versus the long-term objective of developing domain experitise 
and critical thinking skills. When students turn to AI tools for assitance, they risk bypassing the very processes throughwhich such experitise is built.

The tendency to accept or reject AI outputs refects broader patterns in human information processign anddecision-making, particulary when engaging with intelligent systems.
Vasconceloset al. proposed taht users engage in an unconscious cognitive cost-benefit calculation when deciding whether to verfy AI outputsor accept them uncritically.
This framework aligns with dual processtheory outlined in, which distinguishes between fast, intuitive"System 1" thinking and slow, analytical 




新しい論文：

AS AI systems continue to spread and become integrated nto mny aspects of society, the concept of human-centered AI has gained increasing prominence(the state of being easily seen or well known), raising the critical question of which humans
are the AI systems to be centered around.

As artificial intelligence(AI) systems continue to be integrated(consisting of different groups of people who mix, live or 
work well together) into many aspects of society, spanning domains such as healthcare, education, agriculture, and transportation, the concept of human centered AI has gained increasing prominence.






