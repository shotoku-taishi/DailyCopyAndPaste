Abstract. The increasing availability and use of artificial intelligence (AI) tools in educational settings has raised concerns about student`s overreliance on these technologies. 
Overreliance occurs when individuals accept incorrrect AI-generated recommendations, often without critical evaluation, leading to flawed problem solutions and undermining learning
ouccomes. This study investigates potential factors ontributing to patterns of AI reliance among undergraduate students, examining not only overreliance but also apprpriate 
reliance (correctly accepting helpful and rejecting harmful recommendations) and underreliance (incorrectly rejecting helpful recommendations). Our approach comvinedpre- and post-surveys
with a controlled ex@erimental task where participants solved programming problems with an AI assistant that provided both accurate and deliberately incorrect suggestions, allowing
direct observation of students' programming self-efficiency, programming literacy, and need for cognition(The mental action or process of acquiring knowledge and understanding through 
tought, experience, and the senses.), while showing negative correlations with post-task trust and satisfaction. Overreliance showed significant correlations with post-task trust and satisfaction
with the AI assistant. Underreliance was negatively corelated with post-task trust and satisfaction with the AI assistant. Undereliance was negatively correlated with programming 
literacy, programming self-efficacy, and need for cognition. Overall, the findings provid insights for developing targeted interventions that promote appropriate reliance on AI tools, with implications 
for the integration of AI in curriculum and educational technoogies.


In short: currently, many students rely on AI tools to complete their school homeworks. Overreliance on AI tools are correlated with the sel-efficacy, programming literay, and need 
for cognition. In this document, we will learn appropriate was to use AI tool for school carriculum.


The use of artificial intelligence (AI) in higher education has increased dramatically with the development of large language models such as OpenAI's Chat GPT, ANthropic's Claude,
and Microsoft's Copliot. These AI assistants offer students easy to access, and often times, free support in tasks through instant feedback, explanations, and problem solving 
assistance. Student's adoption of these technologies has been substantial, with recent research finding that 64.5% of surveyed undergraduate students use AI chatbots at leas once 
a week.with 90.4%reporting prior experience with these systems. While prior research has examined why students initially adopt AI tools, focusign on factors like perceived
usefulness and ease of use, the widespread adoption of these tools has introduced a new challenge that remains understudiedl students' reliance on AI. Following the frame work obtained by
[28], we distinguish between three primary forms of reliance: appripriate reliance, overreliance, and underreliance. Appropriate reliance occurs when students correctly accept
helpful AI reccommendations and reject flawed(not perfect, or containing mistakes) ones, demonstrating calibrated trust and critical evaluationl overreliance occurs when users 
acept flawed or incorrect AI-generated recommendations without verification; and underreliance occurs when students reject accurate AI recommendations.

When students overrely on AI outputs, it can undermine learning outcomes and reduce their development of critical thinking skills. AI hallucinations(false perception of objects or 
events involving your senses sight, sound, smell, touch and taste.) can introduce "inaccuracies or fabrications(writing in a fictional form.)" that can propagate through academic
work. Students themselves express concerns about peers using AI "as a crutch" and losing the ability to think for themsleves. These concerns are particularly sailent
in education, where students face competing pressures: the immediate need to complete assignments efficiently versus the long-term objective of developing domain experitise 
and critical thinking skills. When students turn to AI tools for assitance, they risk bypassing the very processes throughwhich such experitise is built.

The tendency to accept or reject AI outputs refects broader patterns in human information processign anddecision-making, particulary when engaging with intelligent systems.
Vasconceloset al. proposed taht users engage in an unconscious cognitive cost-benefit calculation when deciding whether to verfy AI outputsor accept them uncritically.
This framework aligns with dual processtheory outlined in, which distinguishes between fast, intuitive"System 1" thinking and slow, analytical 




新しい論文：

AS AI systems continue to spread and become integrated nto mny aspects of society, the concept of human-centered AI has gained increasing prominence(the state of being easily seen or well known), raising the critical question of which humans
are the AI systems to be centered around.

As artificial intelligence(AI) systems continue to be integrated(consisting of different groups of people who mix, live or 
work well together) into many aspects of society, spanning domains such as healthcare, education, agriculture, and transportation, the concept of human centered AI has gained increasing prominence. Human-centered AI involves placing humans at the center of every phase of AI design and deployment. This includes identifying societal problems that are suitable for AI-enabled soluttions, collectign real-world training datasets, and using AI techniques that do not lead to harms such as discrimination. Human-centred AI also emphasizes, transparency(the quality or state of being transparent(Capable of transmitting light so that objects or images can be seen as if there were no intervening material. )), explainability, and adaptability to different human contexts, and it places emphasis on evaluations that ensure the Ai systems benefit those directly affected, while also identifying and addressing any negative consequences before widespread adoption.

Yet, this raises a critical question; which humans are these systems centered around, and what are the implications of who is represented 
and who is not? 
Despite the promise of AI to enhance lives globally, many AI systems fail to address socially relevant problems or attempt to address problems that are 
relevant to selected few. THis is party(person or group taking one side of question, dispute, or contest) because the focus in 
AI development has ben primarily from the systems perspectie,rather than on the humans impacted by these systems. Further, ofr the systems developed to date, we have seen significant disparities in how benefits and harms are distributed across different
communities.

This quadrennnial paper explores the need to place the emphasis on human in human in human-centered AI. It callls for learning from  fields such as Human-Computer Interaction and Science and Technology Studies, which have a long history of including humans in technology design and evaluation, and making informed decisions about when qeual representation in AI development and deployment is beneficial or harmful to the impacted groups. The paper highlights opportunities for human-centred AI that shift the focus from the AI systems to the humans and considers a broad(very wide) spectrum(a range of different positions, opnions, etc. between two extreme points:) of human experiences and needs.


Support the Development of AI(refers to computer systems that can perform complextasks normally done by human-reasoning, decisio making creating.etc. There is no single, ismple definition of artificial intelligence becaue AI tools are capable of a wide rane of tasks and oututs. but NASA follows the definition of AI found within EO 13960. Any arrtificial system that performs tasks under varying and unpredictable circumstances without significant human oversight, or that can learn from experience and improve performance when exposed to data sets.) SYstems That Respect and Serve a Broad Spectrum of Human Experiences.

Why is human-centered AI important, especially o serve andprotect different groups? Human-centered design is critical to the AI development processbecause it can pinpoint aspects that technologists focusing on technical solutions may otherwsise miss. FOr example, when HealthCare.gov launched in 2013, in addition ot the issues of system performance, many users found the website dificult usedue to consusing navigation, a lack of explanation for complex insurance terms, and overwhelming information. A human-centeed approach could have conducted user studies with a diverse applicant pool to uncover and remedy() issues before deployment().







